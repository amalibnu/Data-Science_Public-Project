{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e681108c",
   "metadata": {},
   "source": [
    "Perform text classification on the **Reuters corpus**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "032a5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a131b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Reuters data\n",
    "documents = reuters.fileids()\n",
    "texts = [reuters.raw(doc_id) for doc_id in documents]\n",
    "labels = [reuters.categories(doc_id) for doc_id in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f60b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10788"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "305df6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['trade'], ['grain'], ['crude', 'nat-gas']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68ccebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'text': texts, 'labels': labels})\n",
    "\n",
    "# Split into train and test sets\n",
    "train_docs = [doc for doc in documents if doc.startswith('train')]\n",
    "test_docs = [doc for doc in documents if doc.startswith('test')]\n",
    "\n",
    "X_train = [reuters.raw(doc_id) for doc_id in train_docs]\n",
    "y_train = [reuters.categories(doc_id) for doc_id in train_docs]\n",
    "X_test = [reuters.raw(doc_id) for doc_id in test_docs]\n",
    "y_test = [reuters.categories(doc_id) for doc_id in test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2191bdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7769\n",
      "7769\n",
      "3019\n",
      "3019\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79cefe72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cocoa'],\n",
       " ['acq'],\n",
       " ['money-supply'],\n",
       " ['acq'],\n",
       " ['earn'],\n",
       " ['earn'],\n",
       " ['acq', 'trade'],\n",
       " ['earn'],\n",
       " ['crude', 'nat-gas'],\n",
       " ['cocoa', 'coffee', 'sugar']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f81c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiLabel Binarizer\n",
    "y_train_bin = MultiLabelBinarizer().fit_transform(y_train)\n",
    "y_test_bin = MultiLabelBinarizer().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c539828d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bin[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10af9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing methods\n",
    "\n",
    "# Preprocessing-1: Basic\n",
    "# Convert to lowercase\n",
    "# Word tokenization\n",
    "def basic_preprocessing(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocessing-2: Advanced-Lemmatization\n",
    "# Convert to lowercase\n",
    "# Word tokenization\n",
    "# Stopword Removal\n",
    "# Punctuation Removal\n",
    "# Lemmatization\n",
    "def advanced_lemmatization(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in tokens if word.isalnum() and word not in stopwords])\n",
    "\n",
    "# Preprocessing-3: Advanced-Stemming\n",
    "# Convert to lowercase\n",
    "# Word tokenization\n",
    "# Stopword Removal\n",
    "# Punctuation Removal\n",
    "# Stemming using Porter stemmer algorithm\n",
    "def advanced_stemming(text):\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    return ' '.join([stemmer.stem(word) for word in tokens if word.isalnum() and word not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22ba8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "X_train_basic = [basic_preprocessing(text) for text in X_train]\n",
    "X_test_basic = [basic_preprocessing(text) for text in X_test]\n",
    "X_train_lemmatized = [advanced_lemmatization(text) for text in X_train]\n",
    "X_test_lemmatized = [advanced_lemmatization(text) for text in X_test]\n",
    "X_train_stemmed = [advanced_stemming(text) for text in X_train]\n",
    "X_test_stemmed = [advanced_stemming(text) for text in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f366e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization (TF-IDF)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf_basic = tfidf_vectorizer.fit_transform(X_train_basic)\n",
    "X_test_tfidf_basic = tfidf_vectorizer.transform(X_test_basic)\n",
    "X_train_tfidf_lemmatized = tfidf_vectorizer.fit_transform(X_train_lemmatized)\n",
    "X_test_tfidf_lemmatized = tfidf_vectorizer.transform(X_test_lemmatized)\n",
    "X_train_tfidf_stemmed = tfidf_vectorizer.fit_transform(X_train_stemmed)\n",
    "X_test_tfidf_stemmed = tfidf_vectorizer.transform(X_test_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8415d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classifiers using OneVsRestClassifier\n",
    "models = {\n",
    "    \"Naive Bayes (Basic)\": MultinomialNB(),\n",
    "    \"SVM (Basic)\": SVC(),\n",
    "    \"Naive Bayes (Lemmatization)\": MultinomialNB(),\n",
    "    \"SVM (Lemmatization)\": SVC(),\n",
    "    \"Naive Bayes (Stemming)\": MultinomialNB(),\n",
    "    \"SVM (Stemming)\": SVC()\n",
    "}\n",
    "\n",
    "data_variants = {\n",
    "    \"Basic\": (X_train_tfidf_basic, X_test_tfidf_basic),\n",
    "    \"Lemmatization\": (X_train_tfidf_lemmatized, X_test_tfidf_lemmatized),\n",
    "    \"Stemming\": (X_train_tfidf_stemmed, X_test_tfidf_stemmed)\n",
    "}\n",
    "\n",
    "accuracy_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4743ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    print(f\"\\n{name} Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17af36da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes (Basic Preprocessing) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.36      0.53       719\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00        18\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.00      0.00      0.00        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00        56\n",
      "          13       0.00      0.00      0.00        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       1.00      0.02      0.03       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.99      0.91      0.95      1087\n",
      "          22       0.00      0.00      0.00        10\n",
      "          23       0.00      0.00      0.00        17\n",
      "          24       0.00      0.00      0.00        35\n",
      "          25       0.00      0.00      0.00        30\n",
      "          26       1.00      0.03      0.05       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         5\n",
      "          30       0.00      0.00      0.00         6\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00       131\n",
      "          35       0.00      0.00      0.00        12\n",
      "          36       0.00      0.00      0.00        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00        19\n",
      "          46       0.00      0.00      0.00       179\n",
      "          47       0.00      0.00      0.00        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.00      0.00      0.00        47\n",
      "          55       0.00      0.00      0.00        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00        12\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       0.00      0.00      0.00         9\n",
      "          66       0.00      0.00      0.00        18\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00        24\n",
      "          69       0.00      0.00      0.00        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00        89\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       0.00      0.00      0.00        10\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.00      0.00      0.00        33\n",
      "          77       0.00      0.00      0.00        11\n",
      "          78       0.00      0.00      0.00        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       0.00      0.00      0.00        12\n",
      "          84       0.00      0.00      0.00       117\n",
      "          85       0.00      0.00      0.00        37\n",
      "          86       0.00      0.00      0.00        71\n",
      "          87       0.00      0.00      0.00        10\n",
      "          88       0.00      0.00      0.00        14\n",
      "          89       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       0.99      0.33      0.50      3744\n",
      "   macro avg       0.04      0.01      0.02      3744\n",
      "weighted avg       0.57      0.33      0.38      3744\n",
      " samples avg       0.42      0.41      0.41      3744\n",
      "\n",
      "Naive Bayes (Basic) Training Time: 0.76 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flexi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\flexi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Naive Bayes (Basic)\n",
    "start_time = time.time()\n",
    "X_train_tfidf, X_test_tfidf = data_variants[\"Basic\"]\n",
    "nb_basic = OneVsRestClassifier(MultinomialNB())\n",
    "nb_basic.fit(X_train_tfidf, y_train_bin)\n",
    "y_pred_nb_basic = nb_basic.predict(X_test_tfidf)\n",
    "nb_basic_time = time.time() - start_time\n",
    "nb_basic_acc = evaluate_model(\"Naive Bayes (Basic Preprocessing)\", y_test_bin, y_pred_nb_basic)\n",
    "print(f\"Naive Bayes (Basic) Training Time: {nb_basic_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78820338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM (Basic Preprocessing) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       719\n",
      "           1       1.00      0.13      0.23        23\n",
      "           2       1.00      0.57      0.73        14\n",
      "           3       1.00      0.47      0.64        30\n",
      "           4       1.00      0.11      0.20        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      0.67      0.80        18\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.96      0.86      0.91        28\n",
      "          10       1.00      0.61      0.76        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.97      0.61      0.75        56\n",
      "          13       1.00      0.35      0.52        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       1.00      0.32      0.49        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.95      0.75      0.83       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.85      0.52      0.65        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.99      0.97      0.98      1087\n",
      "          22       1.00      0.20      0.33        10\n",
      "          23       1.00      0.24      0.38        17\n",
      "          24       1.00      0.57      0.73        35\n",
      "          25       0.89      0.53      0.67        30\n",
      "          26       0.98      0.72      0.83       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       1.00      0.60      0.75         5\n",
      "          30       1.00      0.33      0.50         6\n",
      "          31       1.00      0.25      0.40         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.91      0.60      0.72       131\n",
      "          35       1.00      0.33      0.50        12\n",
      "          36       0.83      0.36      0.50        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       1.00      0.52      0.69        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       1.00      0.67      0.80         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.83      0.21      0.33        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00        19\n",
      "          46       0.79      0.66      0.72       179\n",
      "          47       0.92      0.71      0.80        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       1.00      0.27      0.42        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.88      0.32      0.47        47\n",
      "          55       1.00      0.27      0.43        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       1.00      0.50      0.67        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00        12\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       1.00      0.44      0.62         9\n",
      "          66       1.00      0.56      0.71        18\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       1.00      0.12      0.22        24\n",
      "          69       1.00      0.42      0.59        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.90      0.40      0.56        89\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       1.00      0.20      0.33        10\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.91      0.30      0.45        33\n",
      "          77       0.00      0.00      0.00        11\n",
      "          78       0.96      0.69      0.81        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       1.00      0.20      0.33         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       1.00      0.17      0.29        12\n",
      "          84       0.89      0.66      0.75       117\n",
      "          85       1.00      0.38      0.55        37\n",
      "          86       0.96      0.69      0.80        71\n",
      "          87       1.00      0.50      0.67        10\n",
      "          88       0.00      0.00      0.00        14\n",
      "          89       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       0.96      0.72      0.83      3744\n",
      "   macro avg       0.52      0.25      0.32      3744\n",
      "weighted avg       0.91      0.72      0.78      3744\n",
      " samples avg       0.82      0.80      0.81      3744\n",
      "\n",
      "SVM (Basic) Training Time: 435.70 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flexi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\flexi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate SVM (Basic)\n",
    "start_time = time.time()\n",
    "svm_basic = OneVsRestClassifier(SVC())\n",
    "svm_basic.fit(X_train_tfidf, y_train_bin)\n",
    "y_pred_svm_basic = svm_basic.predict(X_test_tfidf)\n",
    "svm_basic_time = time.time() - start_time\n",
    "svm_basic_acc = evaluate_model(\"SVM (Basic Preprocessing)\", y_test_bin, y_pred_svm_basic)\n",
    "print(f\"SVM (Basic) Training Time: {svm_basic_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fc90d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes (Lemmatization) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.42      0.59       719\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00        18\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.00      0.00      0.00        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00        56\n",
      "          13       0.00      0.00      0.00        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       1.00      0.03      0.05       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.99      0.93      0.96      1087\n",
      "          22       0.00      0.00      0.00        10\n",
      "          23       0.00      0.00      0.00        17\n",
      "          24       0.00      0.00      0.00        35\n",
      "          25       0.00      0.00      0.00        30\n",
      "          26       1.00      0.04      0.08       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         5\n",
      "          30       0.00      0.00      0.00         6\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00       131\n",
      "          35       0.00      0.00      0.00        12\n",
      "          36       0.00      0.00      0.00        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00        19\n",
      "          46       1.00      0.04      0.08       179\n",
      "          47       0.00      0.00      0.00        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.00      0.00      0.00        47\n",
      "          55       0.00      0.00      0.00        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00        12\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       0.00      0.00      0.00         9\n",
      "          66       0.00      0.00      0.00        18\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00        24\n",
      "          69       0.00      0.00      0.00        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00        89\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       0.00      0.00      0.00        10\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.00      0.00      0.00        33\n",
      "          77       0.00      0.00      0.00        11\n",
      "          78       0.00      0.00      0.00        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       0.00      0.00      0.00        12\n",
      "          84       0.00      0.00      0.00       117\n",
      "          85       0.00      0.00      0.00        37\n",
      "          86       0.00      0.00      0.00        71\n",
      "          87       0.00      0.00      0.00        10\n",
      "          88       0.00      0.00      0.00        14\n",
      "          89       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       0.99      0.35      0.52      3744\n",
      "   macro avg       0.06      0.02      0.02      3744\n",
      "weighted avg       0.62      0.35      0.40      3744\n",
      " samples avg       0.44      0.44      0.44      3744\n",
      "\n",
      "Naive Bayes (Lemmatization) Training Time: 0.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flexi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\flexi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Naive Bayes (Lemmatization)\n",
    "start_time = time.time()\n",
    "X_train_tfidf, X_test_tfidf = data_variants[\"Lemmatization\"]\n",
    "nb_lemmatized = OneVsRestClassifier(MultinomialNB())\n",
    "nb_lemmatized.fit(X_train_tfidf, y_train_bin)\n",
    "y_pred_nb_lemmatized = nb_lemmatized.predict(X_test_tfidf)\n",
    "nb_lemmatized_time = time.time() - start_time\n",
    "nb_lemmatized_acc = evaluate_model(\"Naive Bayes (Lemmatization)\", y_test_bin, y_pred_nb_lemmatized)\n",
    "print(f\"Naive Bayes (Lemmatization) Training Time: {nb_lemmatized_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15dc4a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM (Lemmatization) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       719\n",
      "           1       1.00      0.22      0.36        23\n",
      "           2       1.00      0.57      0.73        14\n",
      "           3       1.00      0.43      0.60        30\n",
      "           4       1.00      0.17      0.29        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      0.67      0.80        18\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.96      0.86      0.91        28\n",
      "          10       1.00      0.56      0.71        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.97      0.61      0.75        56\n",
      "          13       1.00      0.40      0.57        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       1.00      0.32      0.49        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.94      0.76      0.84       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.89      0.55      0.68        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.99      0.97      0.98      1087\n",
      "          22       1.00      0.20      0.33        10\n",
      "          23       1.00      0.29      0.45        17\n",
      "          24       1.00      0.54      0.70        35\n",
      "          25       0.89      0.53      0.67        30\n",
      "          26       0.98      0.77      0.86       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       1.00      0.60      0.75         5\n",
      "          30       1.00      0.33      0.50         6\n",
      "          31       1.00      0.50      0.67         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.91      0.60      0.72       131\n",
      "          35       1.00      0.33      0.50        12\n",
      "          36       0.83      0.36      0.50        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       1.00      0.52      0.69        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.71      0.21      0.32        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00        19\n",
      "          46       0.81      0.66      0.73       179\n",
      "          47       0.96      0.74      0.83        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.90      0.30      0.45        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.80      0.43      0.56        47\n",
      "          55       1.00      0.45      0.62        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       1.00      0.50      0.67        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00        12\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       1.00      0.44      0.62         9\n",
      "          66       1.00      0.67      0.80        18\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       1.00      0.17      0.29        24\n",
      "          69       1.00      0.42      0.59        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.94      0.52      0.67        89\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       1.00      0.20      0.33        10\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.76      0.48      0.59        33\n",
      "          77       0.00      0.00      0.00        11\n",
      "          78       1.00      0.72      0.84        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       1.00      0.20      0.33         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       1.00      0.17      0.29        12\n",
      "          84       0.87      0.64      0.74       117\n",
      "          85       1.00      0.38      0.55        37\n",
      "          86       0.94      0.70      0.81        71\n",
      "          87       1.00      0.30      0.46        10\n",
      "          88       0.00      0.00      0.00        14\n",
      "          89       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       0.96      0.73      0.83      3744\n",
      "   macro avg       0.51      0.27      0.33      3744\n",
      "weighted avg       0.91      0.73      0.79      3744\n",
      " samples avg       0.83      0.81      0.81      3744\n",
      "\n",
      "SVM (Lemmatization) Training Time: 303.83 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flexi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\flexi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate SVM (Lemmatization)\n",
    "start_time = time.time()\n",
    "svm_lemmatized = OneVsRestClassifier(SVC())\n",
    "svm_lemmatized.fit(X_train_tfidf, y_train_bin)\n",
    "y_pred_svm_lemmatized = svm_lemmatized.predict(X_test_tfidf)\n",
    "svm_lemmatized_time = time.time() - start_time\n",
    "svm_lemmatized_acc = evaluate_model(\"SVM (Lemmatization)\", y_test_bin, y_pred_svm_lemmatized)\n",
    "print(f\"SVM (Lemmatization) Training Time: {svm_lemmatized_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5afe5406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes (Stemming) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60       719\n",
      "           1       0.00      0.00      0.00        23\n",
      "           2       0.00      0.00      0.00        14\n",
      "           3       0.00      0.00      0.00        30\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00        18\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.00      0.00      0.00        28\n",
      "          10       0.00      0.00      0.00        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       1.00      0.05      0.10        56\n",
      "          13       0.00      0.00      0.00        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       1.00      0.03      0.06       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       1.00      0.92      0.96      1087\n",
      "          22       0.00      0.00      0.00        10\n",
      "          23       0.00      0.00      0.00        17\n",
      "          24       0.00      0.00      0.00        35\n",
      "          25       0.00      0.00      0.00        30\n",
      "          26       1.00      0.04      0.08       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         5\n",
      "          30       0.00      0.00      0.00         6\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00       131\n",
      "          35       0.00      0.00      0.00        12\n",
      "          36       0.00      0.00      0.00        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       0.00      0.00      0.00        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       0.00      0.00      0.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00        19\n",
      "          46       1.00      0.04      0.08       179\n",
      "          47       0.00      0.00      0.00        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.00      0.00      0.00        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.00      0.00      0.00        47\n",
      "          55       0.00      0.00      0.00        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00        12\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       0.00      0.00      0.00         9\n",
      "          66       0.00      0.00      0.00        18\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.00      0.00      0.00        24\n",
      "          69       0.00      0.00      0.00        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00        89\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       0.00      0.00      0.00        10\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.00      0.00      0.00        33\n",
      "          77       0.00      0.00      0.00        11\n",
      "          78       0.00      0.00      0.00        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       0.00      0.00      0.00         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       0.00      0.00      0.00        12\n",
      "          84       0.00      0.00      0.00       117\n",
      "          85       0.00      0.00      0.00        37\n",
      "          86       0.00      0.00      0.00        71\n",
      "          87       0.00      0.00      0.00        10\n",
      "          88       0.00      0.00      0.00        14\n",
      "          89       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       1.00      0.36      0.52      3744\n",
      "   macro avg       0.07      0.02      0.02      3744\n",
      "weighted avg       0.63      0.36      0.40      3744\n",
      " samples avg       0.44      0.44      0.44      3744\n",
      "\n",
      "Naive Bayes (Stemming) Training Time: 0.72 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flexi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\flexi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Naive Bayes (Stemming)\n",
    "start_time = time.time()\n",
    "X_train_tfidf, X_test_tfidf = data_variants[\"Stemming\"]\n",
    "nb_stemmed = OneVsRestClassifier(MultinomialNB())\n",
    "nb_stemmed.fit(X_train_tfidf, y_train_bin)\n",
    "y_pred_nb_stemmed = nb_stemmed.predict(X_test_tfidf)\n",
    "nb_stemmed_time = time.time() - start_time\n",
    "nb_stemmed_acc = evaluate_model(\"Naive Bayes (Stemming)\", y_test_bin, y_pred_nb_stemmed)\n",
    "print(f\"Naive Bayes (Stemming) Training Time: {nb_stemmed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ba591a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM (Stemming) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       719\n",
      "           1       1.00      0.22      0.36        23\n",
      "           2       1.00      0.57      0.73        14\n",
      "           3       0.93      0.43      0.59        30\n",
      "           4       1.00      0.17      0.29        18\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      0.67      0.80        18\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.96      0.86      0.91        28\n",
      "          10       1.00      0.67      0.80        18\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.95      0.62      0.75        56\n",
      "          13       1.00      0.40      0.57        20\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       1.00      0.32      0.49        28\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.94      0.76      0.84       189\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.86      0.55      0.67        44\n",
      "          20       0.00      0.00      0.00         4\n",
      "          21       0.99      0.98      0.98      1087\n",
      "          22       1.00      0.20      0.33        10\n",
      "          23       1.00      0.29      0.45        17\n",
      "          24       1.00      0.60      0.75        35\n",
      "          25       0.88      0.50      0.64        30\n",
      "          26       0.98      0.78      0.87       149\n",
      "          27       0.00      0.00      0.00         4\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       1.00      0.60      0.75         5\n",
      "          30       1.00      0.33      0.50         6\n",
      "          31       1.00      0.50      0.67         4\n",
      "          32       0.00      0.00      0.00         7\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.89      0.63      0.74       131\n",
      "          35       1.00      0.17      0.29        12\n",
      "          36       0.86      0.43      0.57        14\n",
      "          37       0.00      0.00      0.00         1\n",
      "          38       1.00      0.52      0.69        21\n",
      "          39       0.00      0.00      0.00         2\n",
      "          40       0.00      0.00      0.00        14\n",
      "          41       1.00      1.00      1.00         3\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.75      0.25      0.38        24\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00        19\n",
      "          46       0.82      0.68      0.75       179\n",
      "          47       0.93      0.76      0.84        34\n",
      "          48       0.00      0.00      0.00         4\n",
      "          49       0.91      0.33      0.49        30\n",
      "          50       0.00      0.00      0.00         1\n",
      "          51       0.00      0.00      0.00         2\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.80      0.43      0.56        47\n",
      "          55       1.00      0.45      0.62        11\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       1.00      0.50      0.67        10\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00        12\n",
      "          60       0.00      0.00      0.00         7\n",
      "          61       0.00      0.00      0.00         3\n",
      "          62       0.00      0.00      0.00         3\n",
      "          63       0.00      0.00      0.00         1\n",
      "          64       0.00      0.00      0.00         3\n",
      "          65       1.00      0.44      0.62         9\n",
      "          66       1.00      0.67      0.80        18\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       1.00      0.17      0.29        24\n",
      "          69       1.00      0.50      0.67        12\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.94      0.54      0.69        89\n",
      "          72       0.00      0.00      0.00         8\n",
      "          73       1.00      0.20      0.33        10\n",
      "          74       0.00      0.00      0.00        13\n",
      "          75       0.00      0.00      0.00        11\n",
      "          76       0.76      0.48      0.59        33\n",
      "          77       0.00      0.00      0.00        11\n",
      "          78       1.00      0.72      0.84        36\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         2\n",
      "          81       1.00      0.20      0.33         5\n",
      "          82       0.00      0.00      0.00         4\n",
      "          83       1.00      0.25      0.40        12\n",
      "          84       0.88      0.66      0.75       117\n",
      "          85       1.00      0.38      0.55        37\n",
      "          86       0.94      0.70      0.81        71\n",
      "          87       1.00      0.30      0.46        10\n",
      "          88       0.00      0.00      0.00        14\n",
      "          89       0.00      0.00      0.00        13\n",
      "\n",
      "   micro avg       0.96      0.74      0.84      3744\n",
      "   macro avg       0.51      0.27      0.34      3744\n",
      "weighted avg       0.91      0.74      0.80      3744\n",
      " samples avg       0.84      0.82      0.82      3744\n",
      "\n",
      "SVM (Stemming) Training Time: 282.50 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flexi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\flexi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate SVM (Stemming)\n",
    "start_time = time.time()\n",
    "svm_stemmed = OneVsRestClassifier(SVC())\n",
    "svm_stemmed.fit(X_train_tfidf, y_train_bin)\n",
    "y_pred_svm_stemmed = svm_stemmed.predict(X_test_tfidf)\n",
    "svm_stemmed_time = time.time() - start_time\n",
    "svm_stemmed_acc = evaluate_model(\"SVM (Stemming)\", y_test_bin, y_pred_svm_stemmed)\n",
    "print(f\"SVM (Stemming) Training Time: {svm_stemmed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12b11da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy and Training Time Comparison:\n",
      "                         Model  Accuracy  Training Time (s)\n",
      "0          Naive Bayes (Basic)  0.413051           0.758855\n",
      "1                  SVM (Basic)  0.760848         435.702291\n",
      "2  Naive Bayes (Lemmatization)  0.433587           0.644122\n",
      "3          SVM (Lemmatization)  0.770123         303.832131\n",
      "4       Naive Bayes (Stemming)  0.434250           0.719355\n",
      "5               SVM (Stemming)  0.776416         282.498932\n"
     ]
    }
   ],
   "source": [
    "# Create accuracy comparison table\n",
    "accuracy_results = [\n",
    "    (\"Naive Bayes (Basic)\", nb_basic_acc, nb_basic_time),\n",
    "    (\"SVM (Basic)\", svm_basic_acc, svm_basic_time),\n",
    "    (\"Naive Bayes (Lemmatization)\", nb_lemmatized_acc, nb_lemmatized_time),\n",
    "    (\"SVM (Lemmatization)\", svm_lemmatized_acc, svm_lemmatized_time),\n",
    "    (\"Naive Bayes (Stemming)\", nb_stemmed_acc, nb_stemmed_time),\n",
    "    (\"SVM (Stemming)\", svm_stemmed_acc, svm_stemmed_time)\n",
    "]\n",
    "\n",
    "accuracy_df = pd.DataFrame(accuracy_results, columns=['Model', 'Accuracy', 'Training Time (s)'])\n",
    "print(\"\\nModel Accuracy and Training Time Comparison:\")\n",
    "print(accuracy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c17a52",
   "metadata": {},
   "source": [
    "### Conclusion & Improvement\n",
    "\n",
    "1. I use 3 different preprocessing method to compare:  \n",
    "- Basic: Convert to lowercase & word tokenization\n",
    "- Advanced (Lemmatization): Basic + Stopword removal + Punctuation Removal + Lemmatization\n",
    "- Advanced (Stemming): Basic + Stopword removal + Punctuation Removal + Porter Stemming\n",
    "2. I used 2 classification algorithm: Naive Bayes & SVM\n",
    "3. For both model, applying advanced preprocessing gives better result compare to basic preprocessing\n",
    "4. Stemming gives a slightly better results compare to lemmatization, but the difference is insignificant in this case.\n",
    "5. A possible improvement in this model includes:\n",
    "a. Remove rare word that doesn't help classification\n",
    "b. Use unigram to improve context awareness\n",
    "c. User word embedding such as word2vec that better in capture context compare to tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4394d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
